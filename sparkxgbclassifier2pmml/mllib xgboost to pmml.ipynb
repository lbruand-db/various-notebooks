{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bfbb49b-60f4-4a38-81b2-1f53d9573af6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install XGBoost"
    }
   },
   "outputs": [],
   "source": [
    "%pip install xgboost==2.0.3 sklearn2pmml==0.124.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28fa7110-bbf7-458e-a944-a1155d6f5dfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import sklearn2pmml\n",
    "\n",
    "print(f\"xgboost version: {xgboost.__version__}\")\n",
    "print(f\"sklearn2pmml version: {sklearn2pmml.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b877ba26-41a7-4cf4-bccf-b9c0809230ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Training a XGBoost SparkXGBClassifier\n",
    "\n",
    "Runtime DBR 16.4 LTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c78c5e8-1e22-4ba3-ac15-61fa6870a3ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "iris_df['species'] = iris_df['target'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "# Convert to Spark DataFrame\n",
    "iris_spark_df = spark.createDataFrame(iris_df)\n",
    "\n",
    "# Display the dataset\n",
    "display(iris_spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3feaf2cb-314a-429b-a956-046fe240815e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Train XGBoost Model with Spark MLlib"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "# Prepare features using VectorAssembler\n",
    "feature_cols = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "iris_features = assembler.transform(iris_spark_df)\n",
    "\n",
    "# Split data into train (80%) and test (20%)\n",
    "train_df, test_df = iris_features.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Training set size: {train_df.count()}\")\n",
    "print(f\"Test set size: {test_df.count()}\")\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"iris_spark_xgboost\") as run:\n",
    "    # Train XGBoost model using SparkXGBClassifier\n",
    "    spark_xgb = SparkXGBClassifier(\n",
    "        features_col=\"features\",\n",
    "        label_col=\"target\",\n",
    "        num_workers=2,\n",
    "        max_depth=5,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    model = spark_xgb.fit(train_df)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.transform(test_df)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"target\",\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"accuracy\"\n",
    "    )\n",
    "    \n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    \n",
    "    # Log parameters and metrics\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", 5)\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "    mlflow.log_param(\"num_workers\", 2)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.spark.log_model(model, \"spark_xgboost_model\")\n",
    "    \n",
    "    print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"MLflow Run ID: {run.info.run_id}\")\n",
    "\n",
    "# Display predictions with species names\n",
    "display(predictions.select(\"features\", \"target\", \"prediction\", \"probability\", \"species\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31187191-58e3-4727-af83-7c75ae78e3f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Turn the SparkXGBClassifier model into a XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9e9a18d-6157-4629-a762-f9f9584327fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "xgboost_model = model.get_booster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "930e9871-a854-47af-843a-a9327b247c61",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Convert SparkXGBClassifierModel to XGBClassifier"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Create an XGBClassifier with the same parameters\n",
    "xgb_classifier = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss',\n",
    "    objective='multi:softprob',\n",
    "    num_class=3\n",
    ")\n",
    "\n",
    "# Set the underlying booster from the Spark model\n",
    "xgb_classifier._Booster = xgboost_model\n",
    "\n",
    "# Set required sklearn attributes for the classifier\n",
    "xgb_classifier.n_classes_ = 4\n",
    "#xgb_classifier.classes_ = np.array([0, 1, 2])\n",
    "xgb_classifier._n_features = 4\n",
    "\n",
    "print(f\"✓ Converted SparkXGBClassifierModel to XGBClassifier\")\n",
    "print(f\"  Model type: {type(xgb_classifier)}\")\n",
    "print(f\"  Number of classes: {xgb_classifier.n_classes_}\")\n",
    "print(f\"  Classes: {xgb_classifier.classes_}\")\n",
    "print(f\"  Number of features: {xgb_classifier._n_features}\")\n",
    "\n",
    "# Test prediction on a sample\n",
    "X_sample = test_df.sample(False, 0.1)\n",
    "predictions = xgb_classifier.predict(X_sample[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']].toPandas())\n",
    "print(f\"\\nSample predictions: {predictions}\")\n",
    "predictions = model.transform(X_sample)\n",
    "print(f\"\\nSample predictions: {predictions[['prediction']].toPandas()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aa73c4e-b4b2-4939-a77f-3648c4d275db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Save the intermediate XGBClassifier to pmml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fa003cc-ed01-464b-a54a-90f945d55ec9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn2pmml import sklearn2pmml\n",
    "from sklearn2pmml.pipeline import PMMLPipeline\n",
    "\n",
    "# Create a PMML pipeline with the xgb_classifier\n",
    "pipeline = PMMLPipeline([\n",
    "    (\"classifier\", xgb_classifier)\n",
    "])\n",
    "\n",
    "# Export to PMML file\n",
    "pmml_file_path = \"xgboost_iris_model.pmml\"\n",
    "\n",
    "try:\n",
    "    sklearn2pmml(pipeline, pmml_file_path, with_repr=True)\n",
    "    print(f\"✓ Model successfully exported to PMML: {pmml_file_path}\")\n",
    "    \n",
    "    # Verify file was created\n",
    "    import os\n",
    "    if os.path.exists(pmml_file_path):\n",
    "        file_size = os.path.getsize(pmml_file_path)\n",
    "        print(f\"  File size: {file_size:,} bytes\")\n",
    "except Exception as e:\n",
    "    print(f\"Error exporting to PMML: {e}\")\n",
    "    print(f\"\\nError details: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adcc2c39-a370-4bb6-bcf4-ab9ef4eee603",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Get the run ID from the previous MLflow run\n",
    "run_id = run.info.run_id\n",
    "\n",
    "# Log the PMML file as an artifact to the existing run\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    mlflow.log_artifact(pmml_file_path, artifact_path=\"spark_xgboost_model\")\n",
    "    print(f\"✓ PMML file uploaded to MLflow run: {run_id}\")\n",
    "    print(f\"  Artifact path: spark_xgboost_model/xgboost_iris_model.pmml\")\n",
    "    print(f\"  File: {pmml_file_path}\")\n",
    "\n",
    "# Display the MLflow run URL\n",
    "print(f\"\\nView in MLflow: #mlflow/experiments/{mlflow.get_experiment(run.info.experiment_id).experiment_id}/runs/{run_id}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "mllib xgboost to pmml",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
