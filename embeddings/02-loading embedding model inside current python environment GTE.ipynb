{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea2651ce-b831-4cc7-94da-21e7b7187ae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Load embedding model inside current python environment. GTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3172384-9479-4e96-9169-fb281be3ca05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"system.ai.gte_large_en_v1_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "525336ab-27f7-4292-b861-db70cdc96a04",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Improved Model Dependencies Installation"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def install_model_dependencies(model_uri):\n",
    "    \"\"\"\n",
    "    Get and install model dependencies using MLflow\n",
    "    \"\"\"\n",
    "    print(f\"Getting dependencies for model: {model_uri}\")\n",
    "    \n",
    "    try:\n",
    "        # Get model dependencies (returns path to requirements.txt)\n",
    "        deps_file = mlflow.pyfunc.get_model_dependencies(model_uri)\n",
    "        print(f\"Dependencies file: {deps_file}\")\n",
    "        \n",
    "        if deps_file and os.path.exists(deps_file):\n",
    "            print(f\"\\nReading dependencies from: {deps_file}\")\n",
    "            \n",
    "            # Read the requirements file\n",
    "            with open(deps_file, 'r') as f:\n",
    "                requirements = f.read().strip().split('\\n')\n",
    "            \n",
    "            # Filter out empty lines and comments\n",
    "            requirements = [req.strip() for req in requirements if req.strip() and not req.strip().startswith('#')]\n",
    "            \n",
    "            if requirements:\n",
    "                print(f\"Found {len(requirements)} dependencies:\")\n",
    "                for req in requirements:\n",
    "                    print(f\"  - {req}\")\n",
    "                \n",
    "                print(\"\\nInstalling dependencies...\")\n",
    "                # Install using pip\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + requirements)\n",
    "                print(\"✅ Dependencies installed successfully!\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"No dependencies found in requirements file.\")\n",
    "                return True\n",
    "        else:\n",
    "            print(\"No dependencies file found or file doesn't exist.\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing dependencies: {e}\")\n",
    "        return False\n",
    "\n",
    "# Example usage\n",
    "model_uri = f\"models:/{model_name}/2\"\n",
    "success = install_model_dependencies(model_uri)\n",
    "\n",
    "if not success:\n",
    "    print(\"\\nFalling back to manual installation...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"transformers\", \"torch\"])\n",
    "    print(\"✅ Manual dependencies installed!\")\n",
    "\n",
    "print(\"\\nDependencies are ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc8cce2d-027b-4de6-894f-0f065820db0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Loading the model...\")\n",
    "\n",
    "# Now load the model\n",
    "model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "print(f\"✅ Successfully loaded model: {model_name} version 2\")\n",
    "print(f\"Model type: {type(model)}\")\n",
    "print(f\"Model ready for use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee4f3bea-d617-49a8-b62c-5dee196290a5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Test the Embedding Model"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Test the embedding model with sample text\n",
    "sample_texts = [\n",
    "    \"This is a sample sentence for embedding.\",\n",
    "    \"Machine learning models can generate text embeddings.\",\n",
    "    \"Databricks provides powerful AI capabilities.\"\n",
    "]\n",
    "\n",
    "print(\"Generating embeddings for sample texts...\")\n",
    "for i, text in enumerate(sample_texts):\n",
    "    print(f\"{i+1}. {text}\")\n",
    "\n",
    "# Format input as expected by the model (with 'input' column)\n",
    "input_data = pd.DataFrame({'input': sample_texts})\n",
    "\n",
    "# Generate embeddings using the loaded model\n",
    "result = model.predict(input_data)\n",
    "\n",
    "print(f\"\\nModel output structure:\")\n",
    "print(f\"- Type: {type(result)}\")\n",
    "print(f\"- Keys: {list(result.keys())}\")\n",
    "\n",
    "# Extract embeddings from the 'data' key\n",
    "if 'data' in result:\n",
    "    data = result['data']\n",
    "    print(f\"\\nData structure:\")\n",
    "    print(f\"- Type: {type(data)}\")\n",
    "    print(f\"- Length: {len(data) if hasattr(data, '__len__') else 'N/A'}\")\n",
    "    \n",
    "    # Extract embeddings (usually each item in data has an 'embedding' field)\n",
    "    embeddings = []\n",
    "    for item in data:\n",
    "        if isinstance(item, dict) and 'embedding' in item:\n",
    "            embeddings.append(item['embedding'])\n",
    "        else:\n",
    "            print(f\"Item structure: {item}\")\n",
    "    \n",
    "    if embeddings:\n",
    "        embeddings = np.array(embeddings)\n",
    "        print(f\"\\n✅ Successfully extracted embeddings!\")\n",
    "        print(f\"- Shape: {embeddings.shape}\")\n",
    "        print(f\"- Embedding dimension: {embeddings.shape[1]}\")\n",
    "        print(f\"- Number of texts processed: {embeddings.shape[0]}\")\n",
    "        print(f\"- First embedding (first 5 values): {embeddings[0][:5]}\")\n",
    "        \n",
    "        # Calculate similarity between first two embeddings\n",
    "        if len(embeddings) > 1:\n",
    "            similarity = np.dot(embeddings[0], embeddings[1]) / (np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1]))\n",
    "            print(f\"- Cosine similarity between first two texts: {similarity:.4f}\")\n",
    "    else:\n",
    "        print(\"Could not extract embeddings from the data structure\")\n",
    "else:\n",
    "    print(\"No 'data' key found in result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6a94062-1851-4172-af92-04afbdbaa43d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": "A10",
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "02-loading embedding model inside current python environment GTE",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
